{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnosing the samples from MCMC\n",
    "\n",
    "The Achilles heel of computing posterior distributions is, most often than not, the computation of the denominator of Bayes's theorem. Markov Chain Monte Carlo Methods (MCMC), such as Metropolis, Hamiltonian Monte Carlo (and its variants like NUTS) are clever mathematical and computational devices that let's us circumvent this problem. The main idea is based on sampling values of the parameters of interest from an easy to sample distribution and then applying a rule, known as metropolis acceptance criterion, to decide if you accept or not that proposal. This rule is necessary as it provides the proper way of correcting those samples to get samples from the true distribution, _i.e_ the posterior distribution in a Bayesian Analysis. The better performance of NUTS over Metropolis can be explained by the fact that the former uses a clever way to propose values. \n",
    "\n",
    "\n",
    "While MCMC methods can be successfully used to solve a huge variety of Bayesian models, this have some trade-offs. Most notably, MCMC methods can be slow for some problems, such as _Big Data_ problems and what is most important for our current discussion finite MCMC chains are not guaranteed to converge to the true parameter value. Thus, is important to check whether we have a valid sample, otherwise any analysis from it will be totally flawed. This section is focused on diagnosing sample obtained from Markov Chain Monte Carlo Methods.\n",
    "\n",
    "There are several tests we can perform, some are visual and some are quantitative. These tests are designed to spot problems with our samples, but they are unable to prove we have the correct distribution; they can only provide evidence that the sample seems reasonable.\n",
    "\n",
    "\n",
    "If we find problems with the samples, the are many solutions to try:\n",
    "* Increase the number of samples. This is very easy to do, but in general only could help to improve accuracy of a model that is already running without major issues, but in general it will not help with model having serious issues like very bad mixing.\n",
    "* Remove a number of samples from the beginning of the trace. This is know as burn-in and it was a very common practice in the past. Modern probabilistic programming languages (PPLs) such as PyMC and PyStan use a tuning/warm-up phase to help auto-tune the samplers and these first samples are automatically discarded. Thus, in general the first few samples that you get are as good as the last ones and hence the practice of burn-in is much less common today. \n",
    "* Modify sampler parameters, such as increasing the length of the tuning phase, or increase the `target_accept` parameter for the NUTS sampler. Under certain circumstances, PPLs will provide suggestions on what to change.\n",
    "* Transform the data, eg center of standardize it.\n",
    "* Re-parametrize the model, that is, express the model in a different but equivalent way, we will see examples of this in the next sections."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
